{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f949529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39160e68",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45745000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "    if os.path.exists(dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def load_data(type, dir='modified_training_data'):\n",
    "    search_dir = os.path.join(dir, type)\n",
    "\n",
    "    if os.path.exists(search_dir):\n",
    "        x_data_path = os.path.join(search_dir, 'x_train.csv')\n",
    "        y_data_path = os.path.join(search_dir, 'y_train.csv')\n",
    "\n",
    "        x_data = pd.read_csv(x_data_path)\n",
    "        y_data = pd.read_csv(y_data_path)\n",
    "\n",
    "        if 'id' in x_data.columns:\n",
    "            x_data.set_index('id') \n",
    "        if 'id' in y_data.columns:\n",
    "            y_data.set_index('id')\n",
    "\n",
    "        return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0029d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "X_base, y_base = load_data('base')\n",
    "X_test, y_test = load_data('test')\n",
    "X_over, y_over = load_data('oversampling')\n",
    "X_under, y_under = load_data('undersampling')\n",
    "X_smote, y_smote = load_data('smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4caae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_base : (675000, 16)\n",
      "y_base : (675000, 1)\n",
      "X_test : (75000, 16)\n",
      "y_test : (75000, 1)\n",
      "X_over : (1319024, 16)\n",
      "y_over : (1319024, 1)\n",
      "X_under : (180976, 16)\n",
      "y_under : (180976, 1)\n",
      "X_smote : (1187122, 16)\n",
      "y_smote : (1187122, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape of each of them \n",
    "train_list = [X_base, y_base ,X_test, y_test, X_over, y_over, X_under, y_under, X_smote, y_smote]\n",
    "list_name = ['X_base', 'y_base', 'X_test', 'y_test', 'X_over', 'y_over', 'X_under', 'y_under', 'X_smote', 'y_smote']\n",
    "\n",
    "for name, data in zip(list_name,train_list):\n",
    "    print(f\"{name} : {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6bb1a",
   "metadata": {},
   "source": [
    "Experimenting with X_train (over) for starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402faa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_over.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_over.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd707497",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_exp = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_exp = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16bef86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1319024, 16]), torch.Size([1319024, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028c781",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2aa788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050c8124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: \n",
      "    input: torch.Size([1319024, 16])\n",
      "    output: torch.Size([1319024, 32])\n",
      "Layer 2: \n",
      "    input: torch.Size([1319024, 32])\n",
      "    output: torch.Size([1319024, 64])\n",
      "Layer 3: \n",
      "    input: torch.Size([1319024, 64])\n",
      "    output: torch.Size([1319024, 1])\n"
     ]
    }
   ],
   "source": [
    "# Model break down\n",
    "# l0 = nn.Flatten()\n",
    "l1 = nn.Linear(16, 32)\n",
    "l2 = nn.Linear(32, 64)\n",
    "l3 = nn.Linear(64, 1)\n",
    "\n",
    "# Layer list\n",
    "layer_list = [l1, l2, l3]\n",
    "\n",
    "input_tensor = X_train\n",
    "\n",
    "for l_num, layer in enumerate(layer_list):\n",
    "    print(f\"Layer {l_num + 1}: \")\n",
    "    print(f'    input: {input_tensor.shape}')\n",
    "    input_tensor = layer(input_tensor)\n",
    "    print(f'    output: {input_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e533c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6171ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(675000, 16)\n",
    "model = NeuralNetwork()\n",
    "logits = model(X)\n",
    "# pred_probab = nn.Sigmoid()(logits)\n",
    "y_pred = logits.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a99f66f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9ff63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([675000]), torch.Size([1319024, 1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9ccd608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_epoch_data(epoch_data, csv_file_path=\"training-log/nn_base_2.csv\"):\n",
    "    if os.path.exists(csv_file_path):\n",
    "        with open(\"training-log/nn_base_2.csv\", 'a') as csv_file:\n",
    "            csvwriter = csv.writer(csv_file)   \n",
    "            csvwriter.writerow(epoch_data)\n",
    "    else:\n",
    "        with open(\"training-log/nn_base_2.csv\", 'w') as csv_file:\n",
    "            csvwriter = csv.writer(csv_file)\n",
    "            header_row = ['Epoch', 'train-loss']\n",
    "            csvwriter.writerow(header_row)\n",
    "            csvwriter.writerow(epoch_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99787c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e8ccccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train-loss: 0.0856\n",
      "Epoch: 2, train-loss: 0.0826\n",
      "Epoch: 3, train-loss: 0.0817\n",
      "Epoch: 4, train-loss: 0.0788\n",
      "Epoch: 5, train-loss: 0.0816\n",
      "Epoch: 6, train-loss: 0.0772\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     history\u001b[38;5;241m.\u001b[39mappend(epoch_data)\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train-loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/envTorch/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/envTorch/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/envTorch/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "X_val = X_test_exp\n",
    "y_val = y_test_exp\n",
    "\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X_train[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y_train[i:i+batch_size]\n",
    "\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "\n",
    "        epoch_data = [\n",
    "            epoch+1, loss.item()\n",
    "        ]\n",
    "        save_epoch_data(epoch_data)\n",
    "        history.append(epoch_data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}, train-loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb443c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.915453314781189\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_exp)\n",
    " \n",
    "accuracy = (y_pred.round() == y_test_exp).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878fa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8310],\n",
       "        [0.0017],\n",
       "        [0.4578],\n",
       "        ...,\n",
       "        [0.0775],\n",
       "        [0.1478],\n",
       "        [0.1387]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5670fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0.500]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c075a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_data(result_data, csv_file_path=\"training-log/model_nn_result.csv\"):\n",
    "    if os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, 'a') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)   \n",
    "            csvwriter.writerow(result_data)\n",
    "\n",
    "    else:\n",
    "        with open(csv_file_path, 'w') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)   \n",
    "            csvwriter.writerow([\n",
    "                'Name', 'Epochs','batch_size', 'Loss_fn','Optimizer', 'LR', \n",
    "                'Train Data Type', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'ROC_AUC Score'\n",
    "            ])\n",
    "            csvwriter.writerow(result_data)\n",
    "\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nn_base', 50, 32, 'BCE Loss', 'Adam', 0.001, 'OverSampling', 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "result = [   \n",
    "    'nn_base',\n",
    "    50,\n",
    "    32,\n",
    "    'BCE Loss',\n",
    "    'Adam',\n",
    "    0.001,\n",
    "    'OverSampling',\n",
    "    accuracy_score(y_test_exp, y_pred.round()),\n",
    "    precision_score(y_test_exp, y_pred.round()),\n",
    "    recall_score(y_test_exp, y_pred.round()),\n",
    "    f1_score(y_test_exp, y_pred.round()),\n",
    "    roc_auc_score(y_test_exp, y_pred.round())\n",
    "]\n",
    "\n",
    "save_result_data(result_data=result)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nn_base'\n",
    "torch.save(model.state_dict(), f'model/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7da1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
