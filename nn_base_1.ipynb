{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f949529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39160e68",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45745000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "    if os.path.exists(dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def load_data(type, dir='modified_training_data'):\n",
    "    search_dir = os.path.join(dir, type)\n",
    "\n",
    "    if os.path.exists(search_dir):\n",
    "        x_data_path = os.path.join(search_dir, 'x_train.csv')\n",
    "        y_data_path = os.path.join(search_dir, 'y_train.csv')\n",
    "\n",
    "        x_data = pd.read_csv(x_data_path)\n",
    "        y_data = pd.read_csv(y_data_path)\n",
    "\n",
    "        if 'id' in x_data.columns:\n",
    "            x_data.set_index('id') \n",
    "        if 'id' in y_data.columns:\n",
    "            y_data.set_index('id')\n",
    "\n",
    "        return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa0029d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "X_base, y_base = load_data('base')\n",
    "X_test, y_test = load_data('test')\n",
    "X_over, y_over = load_data('oversampling')\n",
    "X_under, y_under = load_data('undersampling')\n",
    "X_smote, y_smote = load_data('smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4caae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_base : (675000, 16)\n",
      "y_base : (675000, 1)\n",
      "X_test : (75000, 16)\n",
      "y_test : (75000, 1)\n",
      "X_over : (1319024, 16)\n",
      "y_over : (1319024, 1)\n",
      "X_under : (180976, 16)\n",
      "y_under : (180976, 1)\n",
      "X_smote : (1187122, 16)\n",
      "y_smote : (1187122, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape of each of them \n",
    "train_list = [X_base, y_base ,X_test, y_test, X_over, y_over, X_under, y_under, X_smote, y_smote]\n",
    "list_name = ['X_base', 'y_base', 'X_test', 'y_test', 'X_over', 'y_over', 'X_under', 'y_under', 'X_smote', 'y_smote']\n",
    "\n",
    "for name, data in zip(list_name,train_list):\n",
    "    print(f\"{name} : {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6bb1a",
   "metadata": {},
   "source": [
    "Experimenting with X_train (over) for starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "402faa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_over.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_over.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd707497",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_exp = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_exp = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16bef86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1319024, 16]), torch.Size([1319024, 1]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0028c781",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2aa788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "050c8124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: \n",
      "    input: torch.Size([1319024, 16])\n",
      "    output: torch.Size([1319024, 32])\n",
      "Layer 2: \n",
      "    input: torch.Size([1319024, 32])\n",
      "    output: torch.Size([1319024, 64])\n",
      "Layer 3: \n",
      "    input: torch.Size([1319024, 64])\n",
      "    output: torch.Size([1319024, 1])\n"
     ]
    }
   ],
   "source": [
    "# Model break down\n",
    "# l0 = nn.Flatten()\n",
    "l1 = nn.Linear(16, 32)\n",
    "l2 = nn.Linear(32, 64)\n",
    "l3 = nn.Linear(64, 1)\n",
    "\n",
    "# Layer list\n",
    "layer_list = [l1, l2, l3]\n",
    "\n",
    "input_tensor = X_train\n",
    "\n",
    "for l_num, layer in enumerate(layer_list):\n",
    "    print(f\"Layer {l_num + 1}: \")\n",
    "    print(f'    input: {input_tensor.shape}')\n",
    "    input_tensor = layer(input_tensor)\n",
    "    print(f'    output: {input_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e533c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6171ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(675000, 16)\n",
    "model = NeuralNetwork()\n",
    "logits = model(X)\n",
    "# pred_probab = nn.Sigmoid()(logits)\n",
    "y_pred = logits.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a99f66f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9ff63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([675000]), torch.Size([1319024, 1]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99787c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e8ccccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, latest loss 0.13824808597564697\n",
      "Epoch 2, latest loss 0.10791900753974915\n",
      "Epoch 3, latest loss 0.10264110565185547\n",
      "Epoch 4, latest loss 0.0932726263999939\n",
      "Epoch 5, latest loss 0.08286255598068237\n",
      "Epoch 6, latest loss 0.08538908511400223\n",
      "Epoch 7, latest loss 0.07572470605373383\n",
      "Epoch 8, latest loss 0.0772310346364975\n",
      "Epoch 9, latest loss 0.07740719616413116\n",
      "Epoch 10, latest loss 0.07713283598423004\n",
      "Epoch 11, latest loss 0.07719448953866959\n",
      "Epoch 12, latest loss 0.08078993111848831\n",
      "Epoch 13, latest loss 0.0743129625916481\n",
      "Epoch 14, latest loss 0.07518178224563599\n",
      "Epoch 15, latest loss 0.07355357706546783\n",
      "Epoch 16, latest loss 0.07345563173294067\n",
      "Epoch 17, latest loss 0.08069223910570145\n",
      "Epoch 18, latest loss 0.07170925289392471\n",
      "Epoch 19, latest loss 0.08592042326927185\n",
      "Epoch 20, latest loss 0.07339471578598022\n",
      "Epoch 21, latest loss 0.08716462552547455\n",
      "Epoch 22, latest loss 0.07323931157588959\n",
      "Epoch 23, latest loss 0.07635320723056793\n",
      "Epoch 24, latest loss 0.06593731045722961\n",
      "Epoch 25, latest loss 0.07846391201019287\n",
      "Epoch 26, latest loss 0.07430151104927063\n",
      "Epoch 27, latest loss 0.08084186166524887\n",
      "Epoch 28, latest loss 0.07991078495979309\n",
      "Epoch 29, latest loss 0.07105222344398499\n",
      "Epoch 30, latest loss 0.07364112138748169\n",
      "Epoch 31, latest loss 0.08059485256671906\n",
      "Epoch 32, latest loss 0.074774369597435\n",
      "Epoch 33, latest loss 0.07802559435367584\n",
      "Epoch 34, latest loss 0.07590073347091675\n",
      "Epoch 35, latest loss 0.07718317210674286\n",
      "Epoch 36, latest loss 0.06931973993778229\n",
      "Epoch 37, latest loss 0.07434667646884918\n",
      "Epoch 38, latest loss 0.0660146176815033\n",
      "Epoch 39, latest loss 0.06905998289585114\n",
      "Epoch 40, latest loss 0.07672061026096344\n",
      "Epoch 41, latest loss 0.07697317004203796\n",
      "Epoch 42, latest loss 0.06775504350662231\n",
      "Epoch 43, latest loss 0.0671168863773346\n",
      "Epoch 44, latest loss 0.06888869404792786\n",
      "Epoch 45, latest loss 0.06868929415941238\n",
      "Epoch 46, latest loss 0.07077604532241821\n",
      "Epoch 47, latest loss 0.07165411114692688\n",
      "Epoch 48, latest loss 0.07813984155654907\n",
      "Epoch 49, latest loss 0.06748420000076294\n",
      "Epoch 50, latest loss 0.06850217282772064\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 32\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X_train[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y_train[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, loss {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb443c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.915453314781189\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_exp)\n",
    " \n",
    "accuracy = (y_pred.round() == y_test_exp).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b878fa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8310],\n",
       "        [0.0017],\n",
       "        [0.4578],\n",
       "        ...,\n",
       "        [0.0775],\n",
       "        [0.1478],\n",
       "        [0.1387]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e5670fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0.500]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c075a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_data(result_data, csv_file_path=\"training-log/model_nn_result.csv\"):\n",
    "    if os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, 'a') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)   \n",
    "            csvwriter.writerow(result_data)\n",
    "\n",
    "    else:\n",
    "        with open(csv_file_path, 'w') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)   \n",
    "            csvwriter.writerow(['Name', 'Epochs','batch_size', 'Loss_fn','Optimizer', 'LR', 'Train Data Type', 'Accuracy', 'Precision', 'Recall', 'F1 score', 'ROC_AUC Score'])\n",
    "            csvwriter.writerow(result_data)\n",
    "\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nn_base', 50, 32, 'BCE Loss', 'Adam', 0.001, 'OverSampling', 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "result = [   \n",
    "    'nn_base',\n",
    "    50,\n",
    "    32,\n",
    "    'BCE Loss',\n",
    "    'Adam',\n",
    "    0.001,\n",
    "    'OverSampling',\n",
    "    accuracy_score(y_test_exp, y_pred.round()),\n",
    "    precision_score(y_test_exp, y_pred.round()),\n",
    "    recall_score(y_test_exp, y_pred.round()),\n",
    "    f1_score(y_test_exp, y_pred.round()),\n",
    "    roc_auc_score(y_test_exp, y_pred.round())\n",
    "]\n",
    "\n",
    "save_result_data(result_data=result)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4ba9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'nn_base'\n",
    "torch.save(model.state_dict(), f'model/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7da1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
